{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pathgan-torch",
   "display_name": "Python 3.8 - pathgan-torch",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Kernel padding experiments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[0.0911, 0.7267, 0.3667],\n",
       "          [0.6877, 0.5025, 0.1365],\n",
       "          [0.0259, 0.6638, 0.1500]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "out_channels = 1\n",
    "in_channels = 1\n",
    "kernel_size = (3,3)\n",
    "weights = torch.rand(out_channels,in_channels, kernel_size[0], kernel_size[1])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0911, 0.7267, 0.3667, 0.0000],\n",
       "          [0.0000, 0.6877, 0.5025, 0.1365, 0.0000],\n",
       "          [0.0000, 0.0259, 0.6638, 0.1500, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "padded = F.pad(weights, [1, 1, 1, 1])\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[0.0911, 0.8179, 1.0934, 0.3667],\n",
       "          [0.7788, 2.0080, 1.7323, 0.5032],\n",
       "          [0.7136, 1.8799, 1.4527, 0.2864],\n",
       "          [0.0259, 0.6897, 0.8138, 0.1500]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "source": [
    "padded_upscale = padded[:, :, 1:, 1:] + padded[:, :, 1:, :-1] + padded[:, :, :-1, 1:] + padded[:, :, :-1, :-1]\n",
    "padded_upscale[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0911, 0.7267, 0.3667, 0.6877, 0.5025, 0.1365, 0.0259, 0.6638, 0.1500]])"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "source": [
    "w_mat = weights.view(weights.size(0), -1)\n",
    "w_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(1.3707)"
      ]
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "source": [
    "from utils import max_singular_value\n",
    "u = torch.FloatTensor(1, w_mat.size(0)).normal_(0, 1).cpu()\n",
    "sigma, _u = max_singular_value(w_mat, u, 1)\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[0.0665, 0.5967, 0.7977, 0.2675],\n",
       "          [0.5682, 1.4650, 1.2639, 0.3671],\n",
       "          [0.5206, 1.3715, 1.0598, 0.2090],\n",
       "          [0.0189, 0.5032, 0.5937, 0.1094]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 152
    }
   ],
   "source": [
    "padded_upscale/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = weights[:, :, 1:, 1:] + weights[:, :, 1:, :-\n",
    "                                            1] + weights[:, :, :-1, 1:] + weights[:, :, :-1, :-1]\n",
    "w_mat = weights.view(weights.size(0), -1)\n",
    "sigma, _u = max_singular_value(w_mat, self.u, 1)\n",
    "self.u.copy_(_u)\n",
    "return weights / sigma"
   ]
  },
  {
   "source": [
    "# _output_padding experiments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def _output_padding(input, output_padding, output_size, stride, padding, kernel_size, dilation=None):\n",
    "        # type: (Tensor, Optional[List[int]], List[int], List[int], List[int], Optional[List[int]]) -> List[int]\n",
    "        if output_size is None:\n",
    "            ret = tuple(output_padding)  # converting to list if was not already\n",
    "        else:\n",
    "            k = input.dim() - 2\n",
    "            if len(output_size) == k + 2:\n",
    "                output_size = output_size[2:]\n",
    "            if len(output_size) != k:\n",
    "                raise ValueError(\n",
    "                    \"output_size must have {} or {} elements (got {})\"\n",
    "                    .format(k, k + 2, len(output_size)))\n",
    "\n",
    "            min_sizes = torch.jit.annotate(List[int], [])\n",
    "            max_sizes = torch.jit.annotate(List[int], [])\n",
    "            for d in range(k):\n",
    "                dim_size = ((input.size(d + 2) - 1) * stride[d] -\n",
    "                            2 * padding[d] +\n",
    "                            (dilation[d] if dilation is not None else 1) * (kernel_size[d] - 1) + 1)\n",
    "                min_sizes.append(dim_size)\n",
    "                max_sizes.append(min_sizes[d] + stride[d] - 1)\n",
    "\n",
    "            for i in range(len(output_size)):\n",
    "                size = output_size[i]\n",
    "                min_size = min_sizes[i]\n",
    "                max_size = max_sizes[i]\n",
    "                if size < min_size or size > max_size:\n",
    "                    raise ValueError((\n",
    "                        \"requested an output size of {}, but valid sizes range \"\n",
    "                        \"from {} to {} (for an input of {})\").format(\n",
    "                            output_size, min_sizes, max_sizes, input.size()[2:]))\n",
    "\n",
    "            res = torch.jit.annotate(List[int], [])\n",
    "            for d in range(k):\n",
    "                res.append(output_size[d] - min_sizes[d])\n",
    "\n",
    "            ret = res\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "input_x = 256\n",
    "input_y = 256\n",
    "\n",
    "inputs = torch.zeros(3, 10, input_x, input_y)\n",
    "inputs.dim()\n",
    "output_padding = _output_padding(input, output_padding=[0,0], output_size=[input_x * 2,input_y * 2], stride=[2,2], padding=[1,1], kernel_size=[3,3], dilation=None)\n",
    "\n",
    "output_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success stride: 2, padding: 0, dilation: 1, kernel_size: 1, failed sizes: 0\nsuccess stride: 2, padding: 0, dilation: 1, kernel_size: 2, failed sizes: 0\nfail stride: 2, padding: 0, dilation: 1, kernel_size: 3, failed sizes: 500\nfail stride: 2, padding: 0, dilation: 1, kernel_size: 4, failed sizes: 500\nfail stride: 2, padding: 0, dilation: 1, kernel_size: 5, failed sizes: 500\nfail stride: 2, padding: 1, dilation: 1, kernel_size: 1, failed sizes: 500\nfail stride: 2, padding: 1, dilation: 1, kernel_size: 2, failed sizes: 500\nsuccess stride: 2, padding: 1, dilation: 1, kernel_size: 3, failed sizes: 0\nsuccess stride: 2, padding: 1, dilation: 1, kernel_size: 4, failed sizes: 0\nfail stride: 2, padding: 1, dilation: 1, kernel_size: 5, failed sizes: 500\nfail stride: 2, padding: 2, dilation: 1, kernel_size: 1, failed sizes: 500\nfail stride: 2, padding: 2, dilation: 1, kernel_size: 2, failed sizes: 500\nfail stride: 2, padding: 2, dilation: 1, kernel_size: 3, failed sizes: 500\nfail stride: 2, padding: 2, dilation: 1, kernel_size: 4, failed sizes: 500\nsuccess stride: 2, padding: 2, dilation: 1, kernel_size: 5, failed sizes: 0\nfail stride: 2, padding: 3, dilation: 1, kernel_size: 1, failed sizes: 500\nfail stride: 2, padding: 3, dilation: 1, kernel_size: 2, failed sizes: 500\nfail stride: 2, padding: 3, dilation: 1, kernel_size: 3, failed sizes: 500\nfail stride: 2, padding: 3, dilation: 1, kernel_size: 4, failed sizes: 500\nfail stride: 2, padding: 3, dilation: 1, kernel_size: 5, failed sizes: 500\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for stride in range(2,3):\n",
    "    for padding in range(0,4):\n",
    "        for dilation in range(1,2):\n",
    "            for kernel_size in range(1,6):\n",
    "                failure = False\n",
    "                sizes = []\n",
    "                for input_size in range(0, 500):\n",
    "                    output_size = input_size * 2\n",
    "                    min_size = (input_size - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + 1\n",
    "                    max_size = min_size + stride - 1\n",
    "                    if output_size < min_size or output_size > max_size:\n",
    "                        failure = True\n",
    "                        sizes.append(input_x)\n",
    "\n",
    "                message = 'fail' if failure else 'success'\n",
    "                print(f'{message} stride: {stride}, padding: {padding}, dilation: {dilation}, kernel_size: {kernel_size}, failed sizes: {len(sizes)}')\n",
    "        \n",
    "       "
   ]
  },
  {
   "source": [
    "from https://stats.stackexchange.com/questions/297678/how-to-calculate-optimal-zero-padding-for-convolutional-neural-networks\n",
    "\n",
    "The possible values for the padding size, ùëÉ, depends the input size ùëä (following the notation of the blog), the filter size ùêπ and the stride ùëÜ. We assume width and height are the same.\n",
    "\n",
    "What you need to ensure is that the output size, (ùëä‚àíùêπ+2ùëÉ)/ùëÜ+1, is an integer. When ùëÜ=1 then you get your first equation ùëÉ=(ùêπ‚àí1)/2 as necessary condition. But, in general, you need to consider the three parameters, namely ùëä, ùêπ and ùëÜ in order to determine valid values of ùëÉ.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Same padding experiments"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import Union\n",
    "\n",
    "def same_padding(conv_layer: Union[nn.Conv2d, nn.ConvTranspose2d], inputs: Tensor):\n",
    "    in_height = inputs.size(2)\n",
    "    in_width = inputs.size(3)\n",
    "    dilation = conv_layer.dilation\n",
    "    kernel_size = conv_layer.kernel_size\n",
    "    filter_size = (dilation[0] * (kernel_size[0] - 1) + 1, dilation[1] * (kernel_size[1] - 1) + 1)\n",
    "\n",
    "    print((in_height, in_width))\n",
    "    print(filter_size)\n",
    "\n",
    "    pad_along_height = dilation[0] * (kernel_size[0] - 1)\n",
    "    pad_along_width = dilation[1] * (kernel_size[1] - 1)\n",
    "\n",
    "    pad_top = pad_along_height // 2\n",
    "    pad_bottom = pad_along_height - pad_top\n",
    "    pad_left = pad_along_width // 2\n",
    "    pad_right = pad_along_width - pad_left\n",
    "\n",
    "    print(f'height: {pad_along_height}, width: {pad_along_width}')\n",
    "    print(f'bottom: {pad_bottom}, top: {pad_top}, left: {pad_left}, right: {pad_right}')\n",
    "\n",
    "    return F.pad(inputs, (pad_left, pad_right, pad_top, pad_bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(122, 51)\n(3, 5)\nheight: 2, width: 4\nbottom: 1, top: 1, left: 2, right: 2\ntorch.Size([64, 3, 122, 51])\ntorch.Size([64, 3, 124, 55])\ntorch.Size([64, 3, 122, 51])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand((64, 3, 122, 51))\n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels=3,out_channels=3,kernel_size=(3,5), stride=1, dilation=1)\n",
    "\n",
    "padded_inputs = same_padding(conv_layer, inputs)\n",
    "output = conv_layer(padded_inputs)\n",
    "\n",
    "print(inputs.size())\n",
    "print(padded_inputs.size())\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}